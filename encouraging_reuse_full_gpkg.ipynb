{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbrlpzz/liminal-ai-prompts/blob/main/encouraging_reuse_full_gpkg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L42sCvXdJaVp"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AffrgeQtLVNy",
        "outputId": "e55d736f-3a0e-4ef4-b427-cf5f08918b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google-generativeai version: 0.7.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import re\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import concurrent.futures\n",
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"google-generativeai version: {genai.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g3eSD9TSi4a"
      },
      "source": [
        "Load Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmmRGchuSUhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8111db3a-04b6-49cd-8e28-b87817aa003a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we5dIBf1JgAd"
      },
      "source": [
        "API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFjNkqSFLZPf",
        "outputId": "af428b50-6fb8-442c-b17f-e1e704ff7b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key (first 5 chars): AIzaS...\n"
          ]
        }
      ],
      "source": [
        "GOOGLE_API_KEY = 'AIzaSyCYamOiF02n84lLXXV-H7mVLWmDOfTQd7M'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "print(f\"API Key (first 5 chars): {GOOGLE_API_KEY[:5]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJEqxGRTcS9"
      },
      "source": [
        "Test Connection and Load Model List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bZyHNPQ5LcdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "af3c9c06-0e27-4f4d-8c5a-fce12f5ba3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of models available: 20\n",
            "- models/chat-bison-001\n",
            "- models/text-bison-001\n",
            "- models/embedding-gecko-001\n",
            "- models/gemini-1.0-pro-latest\n",
            "- models/gemini-1.0-pro\n",
            "- models/gemini-pro\n",
            "- models/gemini-1.0-pro-001\n",
            "- models/gemini-1.0-pro-vision-latest\n",
            "- models/gemini-pro-vision\n",
            "- models/gemini-1.5-pro-latest\n",
            "- models/gemini-1.5-pro-001\n",
            "- models/gemini-1.5-pro\n",
            "- models/gemini-1.5-pro-exp-0801\n",
            "- models/gemini-1.5-flash-latest\n",
            "- models/gemini-1.5-flash-001\n",
            "- models/gemini-1.5-flash\n",
            "- models/gemini-1.5-flash-001-tuning\n",
            "- models/embedding-001\n",
            "- models/text-embedding-004\n",
            "- models/aqa\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    models = list(genai.list_models())\n",
        "    print(f\"Number of models available: {len(models)}\")\n",
        "    for model in models:\n",
        "        print(f\"- {model.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error listing models: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3uMyg6GJmnG"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVTj__CLyjk",
        "outputId": "c76947cd-c27f-482b-ba9c-bc1945d9d6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized successfully\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "    print(\"Model initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing model: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UVXTg2GJtPv"
      },
      "source": [
        "Analyze Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zvTncwBUC7m"
      },
      "outputs": [],
      "source": [
        "def analyze_image_with_retry(image, image_path, max_retries=3, timeout=60):\n",
        "    print(f\"  Analyzing image: {os.path.basename(image_path)}\")\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "            prompt = \"\"\"\n",
        "            Analyze this image of a building and answer the following questions. For each question, choose ONLY from the provided options without providing any additional text:\n",
        "\n",
        "            1. Person present: FALSE or TRUE\n",
        "            2. Dogs/Pets present: FALSE or TRUE\n",
        "            3. Livestock present: FALSE or TRUE\n",
        "            4. Sounds present inside: FALSE or TRUE\n",
        "            5. Lights present inside: FALSE or TRUE\n",
        "            6. Collapsed Roof: FALSE or TRUE\n",
        "            7. Windows: \"No - Close (if all)\" or \"Yes - Open (if any)\" or \"None\"\n",
        "            8. Window Broken: \"None\" or \"True (if any broken)\" or \"False (if all windows intact)\"\n",
        "            9. Shutters: \"None\" or \"Close (if all)\" or \"Open (if any)\"\n",
        "            10. Doorway Curtains: \"None\" or \"Unsecured\" or \"Secured (if any)\"\n",
        "            11. For Sale Sign: FALSE or TRUE\n",
        "            12. Civic Number Condition: \"None\" or \"Decorative / Tiled (if any)\" or \"Not Updated\"\n",
        "            13. Chimney Smoke: FALSE or TRUE\n",
        "            14. Vehicle present in garage or private driveway: FALSE or TRUE\n",
        "            15. Hanging laundry: FALSE or TRUE\n",
        "            16. Personal Belongings Outside: \"None\" or \"Good Condition\" or \"Mixed Condition\" or \"Bad Condition\"\n",
        "            17. Mail accumulation: \"None\" or \"Minimal\" or \"Extensive\"\n",
        "            18. Plants / Gardens: \"None\" or \"Well maintained (any)\" or \"Overgrown/Dead\"\n",
        "            19. Perceived Balcony Damage: \"Mild Damage (cracking in plaster in facade)\" or \"No balcony\" or \"Severe Damage (visible rebar)\" or \"No Damage (good condition)\"\n",
        "            20. Perceived Private Staircase Damage: \"No private staircases\" or \"Severe Damage (missing stairs)\" or \"No Damage (good condition)\" or \"Mild Damage (rusted railings)\"\n",
        "            21. Perceived Shutter Damage: \"No Shutters\" or \"No Damage (good condition)\" or \"Mild Damage (needs to be repainted)\" or \"Severe Damage (rotting)\"\n",
        "            22. Door Board: \"None\" or \"Good Condition (any)\" or \"Bad Condition\"\n",
        "\n",
        "            Provide your answers as a numbered list, using ONLY the exact phrases from the options given. DO NOT write any additional text, introduction or explanation.\n",
        "            For example: 22. Door Board: \"None\"\n",
        "            \"\"\"\n",
        "            print(f\"  Sending API request for {os.path.basename(image_path)} (Attempt {attempt + 1}/{max_retries})\")\n",
        "\n",
        "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                future = executor.submit(model.generate_content, [prompt, image])\n",
        "                response = future.result(timeout=timeout)\n",
        "                print(f\"  API request completed for {os.path.basename(image_path)}\")\n",
        "                return response.text\n",
        "        except concurrent.futures.TimeoutError:\n",
        "            print(f\"  API request timed out for {os.path.basename(image_path)} (Attempt {attempt + 1}/{max_retries})\")\n",
        "        except RequestException as e:\n",
        "            print(f\"  Network error for {os.path.basename(image_path)}: {str(e)} (Attempt {attempt + 1}/{max_retries})\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error analyzing image {os.path.basename(image_path)}: {str(e)} (Attempt {attempt + 1}/{max_retries})\")\n",
        "\n",
        "        if attempt < max_retries - 1:\n",
        "            wait_time = 2 ** attempt  # Exponential backoff\n",
        "            print(f\"  Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "    print(f\"  Failed to analyze image {os.path.basename(image_path)} after {max_retries} attempts\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-p9v4LOJ4DL"
      },
      "source": [
        "Assign the image path and start the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZueWgHpZK8m"
      },
      "outputs": [],
      "source": [
        "def process_analysis_result(result_string):\n",
        "    if result_string is None:\n",
        "        return {}\n",
        "    lines = result_string.split('\\n')\n",
        "    result_dict = {}\n",
        "    for line in lines:\n",
        "        parts = line.split(': ', 1)\n",
        "        if len(parts) == 2:\n",
        "            key = parts[0].strip().split('. ', 1)[-1]\n",
        "            value = parts[1].strip().strip('\"')\n",
        "            result_dict[key] = value\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dgks0ZrSt2t"
      },
      "outputs": [],
      "source": [
        "def calculate_occupancy_rating(result_dict):\n",
        "    point_system = {\n",
        "        \"Person present\": {\"FALSE\": 0, \"TRUE\": 4},\n",
        "        \"Dogs/Pets present\": {\"FALSE\": 0, \"TRUE\": 3},\n",
        "        \"Livestock present\": {\"FALSE\": 0, \"TRUE\": 2},\n",
        "        \"Sounds present inside\": {\"FALSE\": 0, \"TRUE\": 2},\n",
        "        \"Lights present inside\": {\"FALSE\": 0, \"TRUE\": 3},\n",
        "        \"Collapsed Roof\": {\"FALSE\": 0, \"TRUE\": -6},\n",
        "        \"Windows\": {\"No - Close (if all)\": 0, \"Yes - Open (if any)\": 2, \"None\": -3},\n",
        "        \"Window Broken\": {\"None\": 0, \"True (if any broken)\": -2, \"False (if all windows intact)\": 1},\n",
        "        \"Shutters\": {\"None\": 0, \"Close (if all)\": -1, \"Open (if any)\": 2},\n",
        "        \"Doorway Curtains\": {\"None\": 0, \"Unsecured\": 2, \"Secured (if any)\": 2},\n",
        "        \"For Sale Sign\": {\"FALSE\": 0, \"TRUE\": -2},\n",
        "        \"Address Number Condition\": {\"None\": 0, \"Decorative / Tiled (if any)\": 1, \"Not Updated\": 0},\n",
        "        \"Chimney Smoke\": {\"FALSE\": 0, \"TRUE\": 3},\n",
        "        \"Vehicle present in garage or private driveway\": {\"FALSE\": 0, \"TRUE\": 2},\n",
        "        \"Hanging laundry\": {\"FALSE\": 0, \"TRUE\": 4},\n",
        "        \"Personal Belongings Outside\": {\"None\": -1, \"Good Condition\": 3, \"Mixed Condition\": 2, \"Bad Condition\": -1},\n",
        "        \"Mail accumulation\": {\"None\": 0, \"Minimal\": -1, \"Extensive\": -1},\n",
        "        \"Plants / Gardens\": {\"None\": 0, \"Well maintained (any)\": 1, \"Overgrown/Dead\": -2},\n",
        "        \"Perceived Balcony Damage\": {\"Mild Damage (cracking in plaster in facade)\": 0, \"No balcony\": 0, \"Severe Damage (visible rebar)\": -3, \"No Damage (good condition)\": 2},\n",
        "        \"Perceived Private Staircase Damage\": {\"No private staircases\": 0, \"Severe Damage (missing stairs)\": -2, \"No Damage (good condition)\": 1, \"Mild Damage (rusted railings)\": 0},\n",
        "        \"Perceived Shutter Damage\": {\"No Shutters\": 0, \"No Damage (good condition)\": 1, \"Mild Damage (needs to be repainted)\": 0, \"Severe Damage (rotting)\": -2},\n",
        "        \"Door Board\": {\"None\": 0, \"Good Condition (any)\": 1, \"Bad Condition\": -2}\n",
        "    }\n",
        "    total_points = sum(point_system[key].get(value, 0) for key, value in result_dict.items() if key in point_system)\n",
        "    return total_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoF_BSK6S3ns"
      },
      "outputs": [],
      "source": [
        "def process_building(building_folder):\n",
        "    print(f\"\\nProcessing building: {os.path.basename(building_folder)}\")\n",
        "    results = []\n",
        "    image_count = 0\n",
        "    for filename in os.listdir(building_folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            image_count += 1\n",
        "            image_path = os.path.join(building_folder, filename)\n",
        "            print(f\"  Opening image: {filename}\")\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                print(f\"  Image opened successfully: {filename}\")\n",
        "                analysis_result = analyze_image_with_retry(image, image_path)\n",
        "                if analysis_result:\n",
        "                    processed_result = process_analysis_result(analysis_result)\n",
        "                    results.append(processed_result)\n",
        "                else:\n",
        "                    print(f\"  Skipping image due to analysis failure: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing image {filename}: {str(e)}\")\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "    print(f\"Completed analysis of {image_count} images for building {os.path.basename(building_folder)}\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNM11JKIS7Vd"
      },
      "outputs": [],
      "source": [
        "def synthesize_building_results(results, building_id):\n",
        "    print(f\"Synthesizing results for building: {building_id}\")\n",
        "    synthesized = {\"Building ID\": building_id}\n",
        "\n",
        "    if not results:\n",
        "        print(f\"No results to synthesize for building {building_id}\")\n",
        "        return synthesized\n",
        "\n",
        "    for key in results[0].keys():\n",
        "        if key == \"Building ID\":\n",
        "            continue\n",
        "\n",
        "        values = [result.get(key) for result in results if result.get(key)]\n",
        "\n",
        "        if key in [\"Person present\", \"Dogs/Pets present\", \"Livestock present\", \"Sounds present inside\",\n",
        "                   \"Lights present inside\", \"Collapsed Roof\", \"For Sale Sign\", \"Chimney Smoke\",\n",
        "                   \"Vehicle present in garage or private driveway\", \"Hanging laundry\"]:\n",
        "            synthesized[key] = \"TRUE\" if \"TRUE\" in values else \"FALSE\"\n",
        "\n",
        "        elif key in [\"Windows\", \"Shutters\"]:\n",
        "            if \"Yes - Open (if any)\" in values or \"Open (if any)\" in values:\n",
        "                synthesized[key] = \"Yes - Open (if any)\" if key == \"Windows\" else \"Open (if any)\"\n",
        "            elif \"No - Close (if all)\" in values or \"Close (if all)\" in values:\n",
        "                synthesized[key] = \"No - Close (if all)\" if key == \"Windows\" else \"Close (if all)\"\n",
        "            else:\n",
        "                synthesized[key] = \"None\"\n",
        "\n",
        "        elif key == \"Window Broken\":\n",
        "            if \"True (if any broken)\" in values:\n",
        "                synthesized[key] = \"True (if any broken)\"\n",
        "            elif \"False (if all windows intact)\" in values:\n",
        "                synthesized[key] = \"False (if all windows intact)\"\n",
        "            else:\n",
        "                synthesized[key] = \"None\"\n",
        "\n",
        "        elif key in [\"Doorway Curtains\", \"Personal Belongings Outside\", \"Mail accumulation\",\n",
        "                     \"Plants / Gardens\", \"Perceived Balcony Damage\", \"Perceived Private Staircase Damage\",\n",
        "                     \"Perceived Shutter Damage\", \"Door Board\"]:\n",
        "            value_priority = {\n",
        "                \"Doorway Curtains\": [\"Secured (if any)\", \"Unsecured\", \"None\"],\n",
        "                \"Personal Belongings Outside\": [\"Good Condition\", \"Mixed Condition\", \"Bad Condition\", \"None\"],\n",
        "                \"Mail accumulation\": [\"Extensive\", \"Minimal\", \"None\"],\n",
        "                \"Plants / Gardens\": [\"Well maintained (any)\", \"Overgrown/Dead\", \"None\"],\n",
        "                \"Perceived Balcony Damage\": [\"Severe Damage (visible rebar)\", \"Mild Damage (cracking in plaster in facade)\", \"No Damage (good condition)\", \"No balcony\"],\n",
        "                \"Perceived Private Staircase Damage\": [\"Severe Damage (missing stairs)\", \"Mild Damage (rusted railings)\", \"No Damage (good condition)\", \"No private staircases\"],\n",
        "                \"Perceived Shutter Damage\": [\"Severe Damage (rotting)\", \"Mild Damage (needs to be repainted)\", \"No Damage (good condition)\", \"No Shutters\"],\n",
        "                \"Door Board\": [\"Bad Condition\", \"Good Condition (any)\", \"None\"]\n",
        "            }\n",
        "            for priority_value in value_priority[key]:\n",
        "                if priority_value in values:\n",
        "                    synthesized[key] = priority_value\n",
        "                    break\n",
        "            else:\n",
        "                synthesized[key] = \"None\"  # Default if no priority value is found\n",
        "\n",
        "        else:  # For any other keys not specifically handled\n",
        "            synthesized[key] = max(set(values), key=values.count) if values else \"None\"\n",
        "\n",
        "    occupancy_rating = calculate_occupancy_rating(synthesized)\n",
        "    synthesized[\"Occupancy Rating\"] = occupancy_rating\n",
        "\n",
        "    print(f\"Synthesis complete for building {building_id}. Occupancy Rating: {occupancy_rating}\")\n",
        "    return synthesized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oldQzGvV6G0N"
      },
      "outputs": [],
      "source": [
        "def process_all_buildings(parent_folder):\n",
        "    all_building_results = []\n",
        "    building_count = 0\n",
        "    processed_count = 0\n",
        "    skipped_count = 0\n",
        "    for building_folder in os.listdir(parent_folder):\n",
        "        building_path = os.path.join(parent_folder, building_folder)\n",
        "        if os.path.isdir(building_path):\n",
        "            building_count += 1\n",
        "            json_path = f\"{building_path}_analysis.json\"\n",
        "\n",
        "            if os.path.exists(json_path):\n",
        "                print(f\"Skipping building {building_folder} - JSON file already exists.\")\n",
        "                skipped_count += 1\n",
        "                # Load existing JSON and add to results\n",
        "                with open(json_path, \"r\") as f:\n",
        "                    existing_result = json.load(f)\n",
        "                all_building_results.append(existing_result)\n",
        "            else:\n",
        "                building_results = process_building(building_path)\n",
        "                synthesized_result = synthesize_building_results(building_results, building_folder)\n",
        "                all_building_results.append(synthesized_result)\n",
        "\n",
        "                # Save individual building result as JSON\n",
        "                with open(json_path, \"w\") as f:\n",
        "                    json.dump(synthesized_result, f, indent=2)\n",
        "                print(f\"Saved analysis for building {building_folder} to {json_path}\")\n",
        "                processed_count += 1\n",
        "\n",
        "    print(f\"Completed analysis of {building_count} buildings\")\n",
        "    print(f\"Processed: {processed_count}, Skipped: {skipped_count}\")\n",
        "    return all_building_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Oe7nwm96KGM"
      },
      "outputs": [],
      "source": [
        "def create_csv(all_building_results, output_file):\n",
        "    if not all_building_results:\n",
        "        print(\"No results to write to CSV.\")\n",
        "        return\n",
        "\n",
        "    # Collect all keys from the dictionaries to form the header of the CSV\n",
        "    keys = set()\n",
        "    for result in all_building_results:\n",
        "        keys.update(result.keys())\n",
        "\n",
        "    # Create an absolute path for the output file\n",
        "    output_path = os.path.abspath(output_file)\n",
        "\n",
        "    # Write the CSV file\n",
        "    with open(output_path, 'w', newline='') as csv_file:\n",
        "        dict_writer = csv.DictWriter(csv_file, fieldnames=list(keys))\n",
        "        dict_writer.writeheader()\n",
        "        dict_writer.writerows(all_building_results)\n",
        "\n",
        "    print(f\"CSV file created: {output_path}\")\n",
        "    return output_path  # Return the path for use in the main function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfuERhw6S90D"
      },
      "outputs": [],
      "source": [
        "def main(parent_folder):\n",
        "    start_time = time.time()\n",
        "    print(f\"Starting analysis of buildings in {parent_folder}\")\n",
        "    all_building_results = process_all_buildings(parent_folder)\n",
        "    csv_file = \"building_analysis_results.csv\"\n",
        "    csv_path = create_csv(all_building_results, csv_file)\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    print(f\"Analysis complete. Results saved in {csv_path}\")\n",
        "    print(f\"Total execution time: {duration:.2f} seconds\")\n",
        "\n",
        "    # Optionally, you can also copy the file to Google Drive\n",
        "    drive_path = \"/content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/\"\n",
        "    drive_csv_path = os.path.join(drive_path, csv_file)\n",
        "    os.system(f\"cp {csv_path} {drive_csv_path}\")\n",
        "    print(f\"CSV file also copied to: {drive_csv_path}\")\n",
        "    return drive_csv_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST\"\n",
        "main(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "xc1pa9XNUQRk",
        "outputId": "3b2a710b-0096-47c8-d8fc-b73958618669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting analysis of buildings in /content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST\n",
            "Skipping building 77 - JSON file already exists.\n",
            "Skipping building 83 - JSON file already exists.\n",
            "Skipping building 85 - JSON file already exists.\n",
            "Skipping building 79 - JSON file already exists.\n",
            "Skipping building 95 - JSON file already exists.\n",
            "Skipping building 100 - JSON file already exists.\n",
            "Skipping building EncouragingReuse_Analysis_Fontainemore_ESPG23032_20240803 - JSON file already exists.\n",
            "Skipping building .ipynb_checkpoints - JSON file already exists.\n",
            "Completed analysis of 8 buildings\n",
            "Processed: 0, Skipped: 8\n",
            "CSV file created: /content/building_analysis_results.csv\n",
            "Analysis complete. Results saved in /content/building_analysis_results.csv\n",
            "Total execution time: 0.07 seconds\n",
            "CSV file also copied to: /content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/building_analysis_results.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/building_analysis_results.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import re\n",
        "\n",
        "def extract_building_id(value):\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    # Convert to string if not already\n",
        "    value_str = str(value)\n",
        "    # Extract the last number from the string\n",
        "    match = re.search(r'(\\d+)(?!.*\\d)', value_str)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def join_shapefile_with_csv(shapefile_path, shapefile_join_field, csv_path, output_gpkg_path):\n",
        "    # Load the shapefile\n",
        "    print(f\"Loading shapefile from: {shapefile_path}\")\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "    print(f\"Shapefile loaded. Number of features: {len(gdf)}\")\n",
        "\n",
        "    # Load the CSV\n",
        "    print(f\"Loading CSV from: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df[df['Building ID'] != '.ipynb_checkpoints']  # Remove .ipynb_checkpoints entry\n",
        "    print(f\"CSV loaded. Number of rows: {len(df)}\")\n",
        "\n",
        "    # Print info about the join field\n",
        "    print(f\"\\nJoin field '{shapefile_join_field}' info:\")\n",
        "    print(gdf[shapefile_join_field].info())\n",
        "    print(\"\\nSample values:\")\n",
        "    print(gdf[shapefile_join_field].head())\n",
        "\n",
        "    # Extract Building ID from shapefile join field\n",
        "    gdf['Extracted_ID'] = gdf[shapefile_join_field].apply(extract_building_id)\n",
        "\n",
        "    # Convert join fields to string in both dataframes\n",
        "    gdf['Extracted_ID'] = gdf['Extracted_ID'].astype(str)\n",
        "    df['Building ID'] = df['Building ID'].astype(str)\n",
        "\n",
        "    print(f\"\\nExtracted ID from shapefile data type: {gdf['Extracted_ID'].dtype}\")\n",
        "    print(f\"Building ID in CSV data type: {df['Building ID'].dtype}\")\n",
        "\n",
        "    # Print unique values and their counts\n",
        "    print(\"\\nUnique extracted IDs in shapefile:\")\n",
        "    print(gdf['Extracted_ID'].value_counts().head())\n",
        "    print(\"\\nUnique values in CSV Building ID:\")\n",
        "    print(df['Building ID'].value_counts())\n",
        "\n",
        "    # Perform the join\n",
        "    print(f\"\\nJoining data on fields: 'Extracted_ID' (shapefile) and 'Building ID' (CSV)\")\n",
        "    gdf_joined = gdf.merge(df, left_on='Extracted_ID', right_on='Building ID', how='left')\n",
        "\n",
        "    # Check for multiple matches\n",
        "    multiple_matches = gdf_joined[gdf_joined.duplicated(subset=['Extracted_ID'], keep=False)]\n",
        "    if not multiple_matches.empty:\n",
        "        print(f\"Warning: {len(multiple_matches)} rows in the result have multiple matches.\")\n",
        "        print(\"Objects with multiple matches:\")\n",
        "        print(multiple_matches['Extracted_ID'].value_counts().head())\n",
        "\n",
        "    print(f\"Join complete. Number of features in result: {len(gdf_joined)}\")\n",
        "\n",
        "    # Check for unmatched rows in shapefile\n",
        "    unmatched = gdf_joined[gdf_joined['Building ID'].isna()]\n",
        "    if not unmatched.empty:\n",
        "        print(f\"\\nWarning: {len(unmatched)} rows in the shapefile did not match any CSV entries.\")\n",
        "        print(\"First few unmatched values from shapefile:\")\n",
        "        print(unmatched['Extracted_ID'].head())\n",
        "\n",
        "    # Check for CSV rows that didn't match any shapefile object\n",
        "    matched_ids = set(gdf_joined['Building ID'].dropna())\n",
        "    unmatched_csv = df[~df['Building ID'].isin(matched_ids)]\n",
        "    if not unmatched_csv.empty:\n",
        "        print(f\"\\nWarning: {len(unmatched_csv)} rows in the CSV did not match any shapefile objects.\")\n",
        "        print(\"Unmatched Building IDs from CSV:\")\n",
        "        print(unmatched_csv['Building ID'].tolist())\n",
        "\n",
        "    # Ensure the GeoDataFrame has the desired CRS (EPSG:3004)\n",
        "    gdf_joined = gdf_joined.to_crs(epsg=3004)\n",
        "    print(f\"\\nGeoDataFrame CRS set to: EPSG:3004\")\n",
        "\n",
        "    # Save as GeoPackage\n",
        "    print(f\"\\nSaving joined data as GeoPackage to: {output_gpkg_path}\")\n",
        "    gdf_joined.to_file(output_gpkg_path, driver='GPKG')\n",
        "    print(\"GeoPackage saved successfully.\")\n",
        "\n",
        "    return output_gpkg_path"
      ],
      "metadata": {
        "id": "ae-smKKip2Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input parameters\n",
        "shapefile_folder = \"/content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST\"\n",
        "shapefile_name = \"EncouragingReuse_Analysis_Fontainemore_ESPG23032_20240803\"\n",
        "shapefile_join_field = \"cd_survey2\"  # Replace with the correct field name if different\n",
        "output_gpkg_name = \"joined_analysis_results.gpkg\"\n",
        "\n",
        "# Construct full paths\n",
        "shapefile_path = os.path.join(shapefile_folder, shapefile_name)\n",
        "drive_path = \"/content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/\"\n",
        "drive_csv_path = \"/content/building_analysis_results.csv\"\n",
        "output_gpkg_path = os.path.join(shapefile_folder, output_gpkg_name)\n",
        "\n",
        "# Run the join operation\n",
        "result_path = join_shapefile_with_csv(shapefile_path, shapefile_join_field, drive_csv_path, output_gpkg_path)\n",
        "print(f\"Operation complete. Result saved to: {result_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1lLyphnp3hG",
        "outputId": "03b4498a-32dc-45bd-8403-4565e97d8195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading shapefile from: /content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/EncouragingReuse_Analysis_Fontainemore_ESPG23032_20240803\n",
            "Shapefile loaded. Number of features: 1787\n",
            "Loading CSV from: /content/building_analysis_results.csv\n",
            "CSV loaded. Number of rows: 7\n",
            "\n",
            "Join field 'cd_survey2' info:\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 1787 entries, 0 to 1786\n",
            "Series name: cd_survey2\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "1787 non-null   int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 14.1 KB\n",
            "None\n",
            "\n",
            "Sample values:\n",
            "0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "Name: cd_survey2, dtype: int64\n",
            "\n",
            "Extracted ID from shapefile data type: object\n",
            "Building ID in CSV data type: object\n",
            "\n",
            "Unique extracted IDs in shapefile:\n",
            "Extracted_ID\n",
            "1889    4\n",
            "59      4\n",
            "117     4\n",
            "1430    4\n",
            "702     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique values in CSV Building ID:\n",
            "Building ID\n",
            "77                                                           1\n",
            "83                                                           1\n",
            "85                                                           1\n",
            "79                                                           1\n",
            "95                                                           1\n",
            "100                                                          1\n",
            "EncouragingReuse_Analysis_Fontainemore_ESPG23032_20240803    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Joining data on fields: 'Extracted_ID' (shapefile) and 'Building ID' (CSV)\n",
            "Warning: 435 rows in the result have multiple matches.\n",
            "Objects with multiple matches:\n",
            "Extracted_ID\n",
            "998     4\n",
            "1889    4\n",
            "702     4\n",
            "868     4\n",
            "59      4\n",
            "Name: count, dtype: int64\n",
            "Join complete. Number of features in result: 1787\n",
            "\n",
            "Warning: 1782 rows in the shapefile did not match any CSV entries.\n",
            "First few unmatched values from shapefile:\n",
            "0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "Name: Extracted_ID, dtype: object\n",
            "\n",
            "Warning: 2 rows in the CSV did not match any shapefile objects.\n",
            "Unmatched Building IDs from CSV:\n",
            "['100', 'EncouragingReuse_Analysis_Fontainemore_ESPG23032_20240803']\n",
            "\n",
            "GeoDataFrame CRS set to: EPSG:3004\n",
            "\n",
            "Saving joined data as GeoPackage to: /content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/joined_analysis_results.gpkg\n",
            "GeoPackage saved successfully.\n",
            "Operation complete. Result saved to: /content/drive/MyDrive/Encouraging Reuse 2024: Fontainemore/TEST/joined_analysis_results.gpkg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF99MoD4ZKrn"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Y2OpboMf5cymRZizZteXW0Gi0yKmQHZq",
      "authorship_tag": "ABX9TyMbz3E7H0VtwBId/QcUA3sh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}